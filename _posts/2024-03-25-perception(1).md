---
title: "2. Perception(1)"
date: 2024-03-25 09:00:00 +0900
categories: ["Autonomous Driving", "Concept"]
tags: ["autonomous driving", "perception"]
use_math: true
---

# 인지 센서

인지에 주로 사용되는 센서는 다음과 같다.

|      | 카메라 | 레이더 | 라이다 |
|------|-------|--------|-------|
| 특징 | ADAS에 가장 많이 사용| 전자기파(RF신호) 의 반사파 분석<br>속도정보를 바로 얻을 수 있음| 고출력 펄스레이저의 반사신호에 대한 시간차 분석|
| 장점 | 높은 해상도<br>저렴한 가격 | 높은 정확도<br>저렴한 가격<br>강인한 성능<br>속도정보 획득가능 | 높은 정확도(먼 거리)<br>강인한 성능
| 단점 | 환경변화에 취약<br> 높은 계산량<br> 낮은 정확도(속도 및 거리)| 높은 오탐률(클러터 현상)<br>횡방향에서 낮은 정확도<br>BEV에서만 표현되는 물체검출 결과| 비싼 가격<br> 습기에 취약|

이 센서들은 차량 주변 환경에 대한 이해를 담당하게 된다.<br>
이 과정에서 센서들은 다음의 2가지 객체에 대한 <u>1) 위치, 2) 종류, 3) 상대속도</u> 등을 식별한다.

ⅰ. 동적환경객체: 차량, 사람, 동물 등<br>
ⅱ. 정적환경객체: 과속방지턱, 표지판, 신호등 등


> **목표**
> 
> - 동적 객체 검출 및 추적
> - 동적 객체의 미래 위치 예측
> - 정적 객체 검출
> - 정적 객체의 정보를 측위에 활용
> - 물체까지의 거리를 측정
>
> ---
> **Dificulty**
>
> 인지부분에서 가장 어려운 점은 근거리에서 100%의 정확도가 보장되어야 할 정도로 높은 정확도가 핵심이라는 것이다.
>
> 하지만 이는 다음과 같은 이유로 인해 매우 어렵다.
>
> - 환경적 다양성
> - 차량과 보행자의 행동 예측
> - 교통 환경의 문맥적 의미 파악 필요
> - 새로운 객체와 물체의 지속적인 업데이트
> 
> 또한 무엇보다도 이를 위해 여러 인지기술을 동시에 수행할 수 있는 하드웨어가 필요하다는 점도 인지 기술이 극복해야 하는 부분이다.

---
## 1. 카메라 
### 1) 요소
![alt text](/assets/img/post/autonomous_driving/camera_part.png)

> 카메라는 빛을 CCD나 CMOS같은 센서를 통해 감지하는 장치이다.<br>
> 주된 구성은 "렌즈", "조리개", "셔터", "몸체"이다.
>
> ---
> #### Notation
> 
> 1. 초점거리(Focal Length)<br>
>   : 렌즈부터 영상이 맺히는 센서사이의 거리
>
> 2. 화각(Field of View, FOV)<br>
>   : 화면을 구성하는 각도
>
> 3. 해상도(Resolution)<br>
>   : 2차원 배열의 크기
>
> 4. Frame Rate<br>
>   : 1초동안 보여주는 이미지의 수
>
> 5. 색상표현<br>
>   : RGB, YIQ, CMY, HIS, ...
> 
> ---
> #### 초점거리와 화각
>
> |     | 망원렌즈 | 표준렌즈 | 광각렌즈 | 어안렌즈 |
> | --- | --- | --- | --- | --- |
> | 화각 | $\sim 40^o$ | $40^o \sim 60^o$ | $60^o \sim 80^o$| $ 180^o \sim$ |
> | FOV | $70\sim 200(mm)$ | $35\sim 38(mm)$ | $15\sim 35(mm)$ | $7\sim 15(mm)$
>
>   - $Focal \, Length\propto \frac{1}{FOV}$
>   - 렌즈에 의한 외곡보정이 필요하다.


### 2) 캘리브레이션(보정)

![alt text](/assets/img/post/autonomous_driving/camera_coordination.png)

> 카메라의 2D이미지를 실제 세계에 Mapping하기 위해서는 보정작업이 필요하다.<br>
> 따라서 캘리브레이션은 2개의 카메라를 활용해 입체적인 촬영을 하는 스테레오 카메라에서 중요하게 사용된다.
>
> 이를 위해서는 변환행렬이 사용되는데, 어떤부분을 Mapping하는지에 따라 **<u>내부파라미터</u>**와 **<u>외부파라미터</u>**로 나뉜다.
> 
> --- 
> #### 1. 좌표계
>
> |     | 설명 | 
> |:---:| --- |
> | 월드 좌표계 | 물체의 위치를 표현할 때 기준으로 삼는 좌표계<br> _(임의로 설정 가능)_ <br>　|
> | 카메라 좌표계 | 1. 카메라의 초점을 원점으로 설정한 좌표계<br>2. 방향<br>　ⅰ. 원점: 카메라의 초점<br>　ⅱ. x축: 카메라의 오른쪽<br>　ⅲ. y축: 카메라의 아래쪽<br>　ⅳ. z축: 카메라의 정면 <br>　|
> | 픽셀 좌표계 | 1. 투영된 이미지의 좌표계<br>2. 방향<br>　ⅰ. 원점: 이미지의 왼쪽 상단<br>　ⅱ. x축: 카메라의 오른쪽<br>　ⅱ. y축: 카메라의 아래쪽 <br>　| 
> | 정규 좌표계 | 카메라 내부 파라미터의 영향이 없을 경우 투영되는 공간에 대한 좌표계 |
>
> ---
> #### 2. 파라미터
>
> ![alt text](/assets/img/post/autonomous_driving/camera_parameter.png)
>
> | | 외부 파라미터 행렬 | 내부 파라미터 행렬 |
> |:---:| --- | --- | 
> | 변환 | 월드좌표계 $\rightarrow$ 카메라 좌표계 | 카메라 좌표 $\rightarrow$ 카메라 영상의 픽셀값<br> _(카메라 내부의 기계적인 셋팅)_ |
> | 요소 | 1. 회전이동<br>2. 평행이동 | 1. 초점거리: 렌즈의 중심과 CCD/CMOS와의 거리<br>2. 주점: 렌즈의 중심에서 이미지 센서에 수직으로 내린 점의 영상픽셀좌표<br> 3. 비대칭 계수: 이미지 센서의 y축이 기울어진 정도<br> 4. 렌즈왜곡<br>5. 영상의 중심값<br>6. 이미지 센서의 Aspect Ratio<br>7. 이미지센서의 Skew Factor<br> |
>
> _(렌즈왜곡 모델: 방사형 렌즈왜곡, 접선형 렌즈왜곡)_
> 
> ---
> #### 3. 캘리브레이션
>
> $$
> w\begin{bmatrix} x & y & 1\end{bmatrix} = \begin{bmatrix} X & Y & Z & 1\end{bmatrix}P
> $$
> 
> |||
> |---|---|
> | $w$       | 스케일 파라미터 |
> | $x, y$    | 카메라 영상의 한점(픽셀위치) |
> | $X, Y, Z$ | 월드 좌표계의 한점의 좌표 |
> | $P$ | 카메라 행렬 |
>
> $$
> P = \begin{bmatrix} R \\ t \end{bmatrix}K
> $$
>
> | 내부 파라미터 | 외부 파라미터 |
> |---|---|
> | $$\begin{bmatrix} R \\ t \end{bmatrix}$$ | $$K = \begin{bmatrix} f_x & 0 & 0\\ s &f_y & 0\\ c_x & c_y & 1\end{bmatrix}$$ |
> | $R \rightarrow$ $3\times 3$의 회전행렬<br> $t \rightarrow$ $1\times 3$의 평행이동 벡터 | $(f_x, f_y) \rightarrow$ 픽셀단위로 표현된 카메라의 초점 길이 <br>$(c_x, c_y) \rightarrow$ 카메라 영상의 중심좌표<br> $s = f_x tan(\alpha) \rightarrow$ skew계수 |
> 
> ---
> #### 4. 방법
>
> 체커보드 촬영 $\rightarrow$ 코너점 검출 $\rightarrow$ 내부 파라미터 및 외부파라미터 계산

### 3) 검출

> #### Detection
> 
> 1. **One Stage Detector**<br>
> ![alt text](/assets/img/post/autonomous_driving/one-stage_detector.png)<br>
> : Classification과 Regional Proposal을 동시에 수행하는 방법.
> 2. **Two-stage Detector**<br>
> ![alt text](/assets/img/post/autonomous_driving/two-stage_detector.png)<br>
> : Classification과 Regional Proposal을 순차적으로 수행하여 결과를 얻는 방법
>   
> ---
> #### Segmentation
> 
> ![alt text](/assets/img/post/autonomous_driving/segmentation.png)
>
> 픽셀별로 물체와 배경을 분류하는 기술

### 4) Tracking

![alt text](/assets/img/post/autonomous_driving/camera_tracking.png)

> Tracking이란 검출 정보를 시간적으로 연결하여 물체별로 ID를 부여하고 추적하는 기술이다.<br>
> 즉, 다음과 같이 "예측 $\rightarrow$ 연결(유사도 기반)"의 과정을 통해 이루어 진다.
> 
> |      | 예측 | 연결(Association) |
> |:----:|-----|-----|
> | 기존 | Kalman Filter | 　　　　　- |
> | 현재 | RNN과 같은 딥러닝 모델<br> _(GNN이라는 기술도 주목받고 있음)_ | 1. Siamese Network<br>　ⅰ. 두개의 비슷한 Network를 사용해 특징값 추출<br>　ⅱ. 특징값 사이의 유사도(거리)를 0~1사이의 값으로 추출<br> 2. 모든 추출 결과들에 대해 유사도를 계산<br>3. 헝가리안 알고리즘을 통해 연결 |
>
> 과거에는 Kalman Filter와 같은 기술을 활용하여 이를 수행했지만,<br>
> 최근에는 딥러닝의 부상으로 GNN이라는 기술이 주목받고 있다.

---
## 2. 레이더

### 1) 종류

| 구분 방식 | 주파수 대역 | 송신 방식 |
| --- | --- | --- |
| 종류 | ⅰ. 24GHz: 근거리용 레이더(SRR)<br>ⅱ. 77GHz: 원거리용 레이더(LRR) | ⅰ. 펄스 레이더<br>ⅱ. 연속파 레이더 |


> #### 펄스 레이더
> 
> 1. 정의<br>
> : 1nm의 짧은 펄스를 송신 및 전파지연시간 측정하는 방식
> 
> 2. 검출 과정<br>
> ⅰ. 주기적으로 펄스를 반송파에 실어 물체 방향으로 송신<br>
> ⅱ. 수신시 지연시간 측정<br>
> ⅲ. 상대거리 예측
>
> 3. 특징<br>
> ⅰ. 펄스의 간격 $\downarrow$ = 거리분해능 $\uparrow$<br>
> ⅱ. 같은 펄스를 사용해야 하기 때문에 하나의 안테나만 사용(송수전환기)<br> 
>   $\rightarrow$ 다음 펄스의 송신 전에 반드시 반사펄스가 들어와야 함
>
> ---
> #### 연속파 레이더
>
> 1. 정의<br>
>   : 시간에 따라 주파수가 변하는 신호를 휴지시간 없이 송신 및 전파지연시간 측정 
> 
> 2. FMCW레이더(주파수 변조 연속파) 구조<br>
>  ![alt text](/assets/img/post/autonomous_driving/fmcwradar.png)<br>
>   믹서: 디처핑을 통해 두 신호의 주파수합-차를 주파수로 갖는 각각의 신호를 발생시킴
> 
> 3. 특징<br>
> ⅰ. 송수신 안테나가 분리<br>
> ⅱ. 비트 주파수를 사용해 샘필링시 하드웨어 비용이 절감됨
> 

### 2) 물체 검출

![alt text](/assets/img/post/autonomous_driving/radar.png)

> #### 검출 과정
> 
> 1. "시간-주파수" 형태의 신호 획득<br>
>   : 수신 신호에 시간에 따라 이동하는 윈도우를 적용해 주파수 성분 변환을 수행한다.
>
> 2. "거리-도플러" 영역으로 환산<br>
>   각 셀에서 신호의 세기를 Threshold를 기준으로 나눔<br>
>   ⅰ. Threshold $\downarrow$: 물체가 아님에도 물체라고 검출할 확률 상승<br>
>   ⅱ. Threshold $\uparrow$: 물체가 있음에도 검출하지 못할 확률 상승
>
> 3. 에너지 관찰<br>
>   : 하나의 셀에 대해 에너지를 보면 물체까지의 거리와 상대속도를 알 수 있다.
>
> ----
> #### CFAR(Constant False Alarm Rate)검출기
>
> 위의 검출과정에서 보면 알 수 있듯이 일정한 Threshold를 통해 검출을 할 경우<br>
> 잡음이나 **클러터**와 같은 방해신호 때문에 일정한 오탐률을 보장할 수 없다.<br>
> *(클러터: 잘못 반사된 신호에 의해 물체가 없는 위치에 신호가 검출되는 것)*
> 
> 즉, 이 Threshold를 적응적으로 조절하는 것이 필요하다
>
> - 셀-평균 CFAR검출<br>
> ![alt text](/assets/img/post/autonomous_driving/cfar.png)<br>
>  : 검출하고자하는 셀의 주변 셀의 정보를 이용해 잡음을 계산한다.
>
> ---
> #### 횡방향 각도 검출
>
> ![alt text](/assets/img/post/autonomous_driving/arrayantenna.png)
>
> 1개의 RADAR는 횡방향에 존재하는 물체에 대한 검출 성능이 떨어진다.<br>
> 이는 배열안테나를 활용해 수신된 내용의 위상 차이를 이용하면 검출할 수 있다..

### 3) 연구 방향

기존의 레이더는 횡방향 해상도가 낮고, 클러터 현상으로 인해 오탐률이 높다는 단점을 가졌다.<br>
최근에는 이를 개선하는 식으로 연구가 진행되고 있고, 대표적인 방법이 다음과 같다.

> | 연구 | 특징 |
> |:----:| --- |
> | 고해상도 레이더 | 1. <u>MIMO안테나</u><br>　: 많은 수의 배열 안테나를 사용해 해상도를 증가시키고 3차원 데이터를 얻는 방법<br><br>2. <u>4D이미지 레이더</u><br>　: 4차원 정보(x, y, z, 속도)를 Point Cloud형태로 제공하는 기술<br>　 |
> | 딥러닝 | 1. 저해상도 레이더의 경우<br>　ⅰ. 신호에 대해 슬라이딩 윈도우를 적용해 2차원 거리-도플러 영상 획득<br> 　ⅱ. 거리-도플러 영상에서 딥러닝을 적용해 조감도 영역에서 2차원 물체 검출<br><br> 2. 고해상도 레이더의 경우 _(라이다의 3차원물체 검출방법 사용)_<br>　ⅰ. 복셀(3차원 블록) 별로 3차원 CNN을 적용해 검출<br>　ⅱ. 포인트 데이터를 조감도 영역에 투영해 2차원 CNN을 적용해 검출<br>　ⅲ. 포인트 넷이라고 하는 포인트 클라우드를 직접 처리하는 방법 사용<br>　|
> | 센서 융합 | 1. 카메라에 레이더 정보를 추가하는 방법<br><br> 2. 카메라와 레이더에서 각각 Feature Map을 추출하여 결합하고<br>　이를 다시 딥러닝을 통해 물체를 검출하는 방법 |
> 

---
## 3. 라이다

기존의 라이다는 905nm의 파장을 사용하였지만, 이 파장은 습도에 영향을 많이 받는다는 단점이 있었다.<br>
이에 최근에는 1550nm의 파장을 사용하는 라이다를 개발하고 있다.

### 1) 종류

| 구분 방식 | 회전 유무 | 구현 방식 |
| --- | --- | --- |
| 종류 | ⅰ. 회전형 라이다<br>ⅱ. 고정형 라이다 | ⅰ. 기계식 라이다<br>ⅱ. MEMS 라이다<br>ⅲ. 플래시 라이다<br>ⅳ. FMCW 라이다 |

> 라이다는 직진성이 강한 고출력 펄스레이저 송신하고 이를 수신하여 지연시간을 분석해 물체를 탐지하고 거리를 측정하는 장치이다.
>
> 이때, 수직방향으로 동시에 송신하는 레이저 빔의 수, 즉 채널수에 따라 Resolution이 달라진다.<br>
> (보통 4채널, 16채널, 32채널, 64채널, 128채널의 제품을 사용)
> 
> ---
> #### 1. 종류별 장단점
>
> | | 회전형(Mechanical) 라이다 | 고정형(Solid State) 라이다 |
> | --- | --- | --- |
> | 탐지방법 | 센서를 기계적으로 회전하여 넓은 각도의 환경정보 획득<br> | 환경정보를 획득하고자 하는 각도에 설치$\cdot$운용 | 
> | 장점 | $360^o$의 전방위 데이터 획들 가능 | 단순한 구성<br>저렴한 가격 |
> | 단점 | 복잡한 구성<br> 비싼 가격<br> 약한 내구성 | 화각이 존재함|
> | 종류 | 기계식 라이다 | MEMS 라이다<br>플래시 라이다<br>OPA 라이다 |
>
> ---
> #### 2. 종류별 탐지 방법
> 
> | | 탐지방법 |
> | --- | --- |
> | **기계식 라이다** | 기계적인 모터를 사용해 탐지<br>*(현재 가장 많이 사용)* |
> | **MEMS 라이다** | MEMS기술로 사용해 작은 반사거울을 제어해 탐지<br>*(MEMS: 나노기술을 사용해 제작되는 매우 작은 기계)*<br> $\rightarrow$ 저온에 취약 |
> | **플래시 라이다** | 송신: 단일레이저 빔을 광시야각으로 확장하여 한번에 송신<br>수신: 다중배열 수신 소자를 통해 반사된 레이저 빔을 수신  |
> | **FMCW 라이다** | 연속적인 신호를 보내고 분석하여 검출하는 방식(FMCW레이더와 비슷)<br> $\rightarrow$ 거리뿐만 아닌 속도 측정도 가능|
> | **OPA 라이다** | Optical Phase Array라는 배열 안테나를 사용해 기계적인 회전이 아닌<br> 안테나 원소의 위상을 조절해 원하는 방향으로 레이저를 발사하고 수신하는 안테나<br>$\rightarrow$ 장거리 탐지시 고출력이 필요해 실제 자율주행에 사용하기에는 어려움 |


### 2) 검출

![alt text](/assets/img/post/autonomous_driving/lidar.png)

> 라이다는 고출력 펄스레이저로 인식하기 때문에 먼 거리의 물체도 정확히 감지가 가능하고 정확도도 매우 높다<br>
>
> 이때, 인식 결과는 4차원 포인트 클라우드이다.<br>
> $\rightarrow$ (x, y, z, intensity)
>
> 이를 표현하는 방식은 다음과 같다.
> - 3차원 박스 표현 + 박스의 회전 각도
> - 2차원 조감도(Bird Eye View)에서 박스 표현 + 박스의 회전 각도
>
> ---
> #### 검출 과정
>
> 라이다의 검출 결과는 순서를 갖지 않는 포인트들의 집합으로, 기존의 2차원 배열을 처리하던 CNN을 사용하기에는 적합하지 않다.
>
> 따라서 포인트 클라우드 데이터 $\rightarrow$ 특징값 추출 $\rightarrow$ 물체검출의 과정을 통해 물체를 찾게된다.
> 
> | 방법 | 설명 | 사례 |
> | --- | --- |:---:|
> | 2차원 평면 투영 | 포인트들을 2차원 평면에 Projection을 해 2차원 데이터를 만든다.<br> $\rightarrow$ 양자화(Quantization)으로 인한 성능 저하 때문에 거의 사용 X| - |
> | 복셀 기반 처리 | 포인트들을 복셀(작은 3차원 큐브)로 나눔<br> $\rightarrow$ 각 복셀별로 포인트들을 인코딩해(ex. 포인트넷) 인베딩 벡터 생성 | 세컨드<br>포인트 필라<br> PV-RCNN |
> | 포인트 넷 | 전체의 포인트 클라우드 집합에 포인트넷 적용<br> $\rightarrow$ 배경과 물체의 포인트를 분리<br> $\rightarrow$ 물체에 포인트를 뽑아 특징값을 계산 | 포인트 RCNN<br> PV-RCNN |
> 
> _(PV-RCNN은 복셀기반 방법과 포인트넷의 혼합방법이다.)_

### 3) Tracking

![alt text](/assets/img/post/autonomous_driving/lidar_tracking.png)

> Tracking이란 검출 정보를 시간적으로 연결하여 물체별로 ID를 부여하고 추적하는 기술이다.<br>
> 즉, 다음과 같이 "3차원 박스 새로 검출 $\rightarrow$ 기존의 박스와 연결" 과정을 통해 이루어 진다.
> 
> |   순서   | 예측 |
> |:----:|-----|
> | 박스 검출 | Kalman Filter<br> _(최근에는 딥러닝의 부상으로 GNN이라는 기술이 주목받고 있다.)_ |
> | 특징값 추출<br> _(딥러닝)_ | **포인트넷**을 사용해 특징값 추출<br>$\rightarrow$ 정보의 손실없이 모든 포인트로부터 특징값 추출 가능 |
> | 유사도 측정<br> _(딥러닝)_ | **Siamese Network**를 사용해 유사도 계산<br>　ⅰ. 두개의 비슷한 Network를 사용해 특징값 추출<br>　ⅱ. 특징값 사이의 유사도(거리)를 0~1사이의 값으로 추출<br>　ⅲ. 모든 추출 결과들에 대해 유사도를 계산<br>　ⅳ. 헝가리안 알고리즘(또는 GNN)을 통해 연결 |
> 
>
> _예시: mmMOT, GNN3DMOT_