---
title: "[Paper Review] DINOv2: Learning Robust Visual Features without Supervision"
date: 2024-12-17 12:00:00 +0900
categories: ["Paper Review", "Self-Supervised Learning"]
tags: ["paper review", "dinov2", "dino"]
use_math: true
---

# Source

> - TMLR 2022 [Paper](https://arxiv.org/pdf/2304.07193), [Git](https://github.com/facebookresearch/dinov2)<br>
> - Maxime Oquab, Timothee Darcet, Theo Moutakanni, Huy V.Vo, Marc Szafraniec, Vasil Khalidov
 <br>
> - 14 Apr 2023<br>
> - (Meta AI Research, Inria)

---
# Contents
## 0. Abstract

최근 자연어 처리(NLP) 분야에서 대규모 데이터로 사전학습된 모델의 성공은 컴퓨터 비전에서도 비슷한 **"Foundation Model"**의 가능성을 열어주었다. 이러한 모델은 **범용적인 시각 특징(General-purpose Visual Features)**을 생성해, 미세 조정 없이도 다양한 이미지 분포와 작업에 활용될 수 있다.

DINOv2 연구는 기존의 자기 지도 학습(Self-supervised Learning) 방법들이 충분히 큐레이션(정제된)된 대규모 데이터셋을 사용하면 이러한 범용 시각 특징을 학습할 수 있음을 보여준다. 이를 위해 다음과 같은 Contribution을 제안한다.
1. Data Pipeline<br>
: 자동화된 Pipeline을 통해 다양하고 정제된 dataset을 얻는 방법
2. Model<br>
: 10억개의 Parameter를 갖는 ViT를 더 작은 모델로 Distillation하여 General Purpose를 갖는 Feature를 얻음.

---
## 1. Instruction

### Previous Work(Text-guided Pregraining)

자연어 처리(NLP) 분야에서는 **Task-agnostic Pretrained Representations**이 표준이 되었다. 이러한 표현들은 미세 조정(Fine-tuning) 없이도 바로 사용할 수 있으며, 특정 태스크에 맞춘 모델보다도 뛰어난 성능을 보여주었다. 이를 바탕으로 컴퓨터 비전에서도 **Foundation Models**이 등장할 것으로 기대되는데, 이러한 모델들은 이미지 수준(ex. 이미지 분류)과 픽셀 수준(ex. 세그멘테이션) 작업에서 바로 사용 가능한 Visual Feature를 생성해야 한다. 현재까지 가장 유망한 Vision Foundation Model들은 Text-guided Pretraining을 중심으로 발전하고 있다. 하지만 이러한 방법들은 Text로는 Image의 풍부한 정보들을 모두 표현하지 못할 뿐더러 학습을 위해서는 Text-image 데이터 뭉치가 필요하기에 raw data만으로 학습하기 어렵다는 한계가 있다.

### Previous Work(Self-Supervised Learning)

**Self-supervised Learning (SSL)**은 이미지 자체에서 특징을 학습하는 방법으로, 텍스트 기반 사전학습의 대안으로 주목받고 있다. 이는 Language Modeling과 같은 Pretext task와 개념적으로 유사하고, Image level과 Pixel level의 정보를 모두 학습할 수 있다. 하지만 대부분의 Self-Supervised Learning연구는 ImageNet과 같이 적은 수의 정제된 데이터만을 가지고 연구되었기 때문에 좋은 Feature를 학습할 수 없었다.

### Approaches

따라서 이 연구에서 우리는 Self-Supervised Learning이 많은 양의 정제된 데이터를 가지고 학습할 때, General-purpose Visual Feature를 학습할 수 있을지에 대한 연구를 진행할 것이다. 그리고 Image와 Patch Level의 Feature를 모두 다룰 수 있는 기존 기법(iBOT)의 Design Choice를 "Large", "Curated" Data에 맞게 수정하고 개선하고자 한다. 그 결과 기존 방법 대비 학습 속도를 2배 빠르게 하고, 메모리 사용량을 3배 감소시킬 수 있었다.

1. Automatic Pipeline<br>
: 이를 위해 Uncurated image를 필터링하고, rebalance하는 자동화된 데이터 Pipeline을 구축했다. 이는 NLP분야의 데이터 처리 기법에서 영감을 받아 설계되었고, Manual Annotation이나 Metadata없이도 데이터를 효율적으로 처리할 수 있게 한다.

2. DINOv2<br>
: 그리고 우리는 DINOv2라는 모델을 제안하고, 위에서 얻은 "Large", "Curated" Data를 통해 학습한 결과 매우 Competitive한 모델을 얻을 수 있었다.

---
## 2. Related Work

### Intra-image self-supervised training

Self-supervised Learning의 첫 번째 방법론은 이미지 자체에서 신호를 추출하는 **Pretext Tasks**에 집중한다. 이러한 작업은 이미지의 일부분을 예측하거나 변형을 복원하는 등 이미지의 일부를 학습 목표로 삼는다. 다음과 같은 Idea들이 있다.
- Predicting Context<br> 주어진 Patch의 상대적인 위치를 예측하는 Pretext Task
- Re-Colorizing<br> 흑백 이미지를 Color이미지로 변환하는 Pretext Task
- Predicting Transformation<br> 이미지의 변형(회전 등)을 예측하는 Pretext Task
- Inpainting, Patch Re-Ordering, Masked Prediction

> 하지만 위의 방법들로부터 얻은 Feature들은 Downstream Task에서 Finetuning이 필요하다는 단점이 있다.

### Discriminative self-supervised learning

Self-supervised Learning의 두 번째 방법론은 이미지 또는 이미지 그룹 간의 **판별 신호(Discriminative Signals)**를 사용하여 특징을 학습하는 방법이다. 이 접근법은 초기 딥러닝 연구에 뿌리를 두고 있으며, 인스턴스 분류와 클러스터링 기법을 기반으로 발전했다.

- Instance-level Objective<br>
: CPC, MoCo, SimSiam, SimCLR, BYOL, DINO

- Clustering based<br>
: Deep Cluster, SeLa, SwAV

> 위의 방법들은 ImageNet과 같은 벤치마크에서는 좋은 성능을 보이지만, 대규모 모델과 데이터셋으로 확장하기 어렵다는 단점이 있다.

### Scaling self-supervised pretraining

최근 연구들은 **Self-supervised Learning (SSL)**의 **확장성(Scaling Abilities)**에 집중하며, 특히 데이터와 모델의 규모가 학습 성능에 미치는 영향을 분석하고 있다. 대부분의 연구들은 "Large", "Uncurated" data를 활용해 Model의 Scale을 늘리는 연구가 많다.

- [Unsupervised pre-training of image features on non-curated data](https://arxiv.org/pdf/1905.01278)
- [Self-supervised pretraining of visual features in the wild](https://arxiv.org/pdf/2103.01988)
- [Scaling and benchmarking self-supervised visual representation learning](https://arxiv.org/pdf/1905.01235)
- [Self-supervised learning from uncurated data](https://arxiv.org/pdf/2105.08054)
- [Vision models are more robust and fair when pretrained on uncurated images without supervision](https://arxiv.org/pdf/2202.08360)

> 하지만 대부분의 방법들은 "Uncurated" data의 품질 저하로 인해 성능이 제한되는 문제가 발생하였다.

### Automatic data curation

이번 연구의 데이터셋 구축 방식은 **이미지 검색(Image Retrieval)** 분야에서 영감을 받았다. 특히 시각적 유사성을 활용해 데이터를 필터링하고 증강하는 접근을 사용하며, 이는 기존의 **Semi-supervised Learning**이나 메타데이터 활용 기법과 차별화될 수 있다. Pretrained된 Encoder와 metadata에 의존했던 기존의 방법들과는 달리, 우리는 Visual Similarity만을 활용해 이미지를 필터링하고 증강한다. 이는 기존의 Text Curation pipeline으로 사용되는 [Ccnet](https://arxiv.org/pdf/1911.00359)에서 영감을 받았다.

## 3. Data Processing

