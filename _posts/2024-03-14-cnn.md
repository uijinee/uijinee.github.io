---
title: "CNN"
date: 2024-03-14 22:00:00 +0900
categories: ["Deep Learning", "Basic"]
tags: ["vision"]
---

## 1. BackGround

### 1) Data

![alt text](/assets/img/post/cnn/horse.png)

> 위의 두 말은 다른 말일까??<br>
> 자세히 보면 오른쪽 말 사진은 왼쪽 사진에서 잘라낸 사진이므로 같은 말임을 알 수 있다.
>
> 하지만 CNN이 아닌 Fully Connected Layer로만 구성된 딥러닝 모델들은 위 두 사진을 전혀 다른 사진으로 판별하게 된다.
>
> 따라서 우리는 이미지 데이터를 해석할 만한 다른 방법이 필요하다.

### 2) Convolution

**Continuous Domain**

- $x(t) * h(t) = \int^{\infty}_{-\infty} x(\tau)h(t-\tau)d\tau$

**Discrete Domain**

- $x[n]*h[n] = \sum\limits_{k=-\infty}^{\infty} x[k]h[n-k]$

> 우리는 위의 문제를 Convolution연산을 통해서 해결해 볼 수 있다.<br>
> 이 Convolution연산의 의미를 알아보기 전에 먼저 행렬에서 Convolution의 계산 방법부터 알아보자.
>
> ![alt text](/assets/img/post/cnn/convolution.png)
>
> (위 그림은 `Padding_size=0`, `Stride=1`인 경우이다.)
>
> ---
>
> #### 1. Paddding
>
> ![alt text](/assets/img/post/cnn/padding.png)
>
> Convolution연산을 잘 살펴보면 행렬의 가장자리에 있는 데이터의 정보는 그렇지 않은 데이터에 비해 연산에 참여하는 횟수가 적다는 것을 확인할 수 있다.
>
> 즉, 가장자리데이터의 정보가 비교적 덜 중요하게 처리된다는 것이다.
>
> 이를 방지하기 위해 가장자리에 임의의 데이터를 추가적으로 채워 넣어주는 것을 Padding이라고 한다.
>
> ---
>
> #### 2. Stride
>
> ![alt text](/assets/img/post/cnn/stride.png)
>
> Stride는 filter가 Convolution 연산 후 이동하는 거리를 의미한다.<br>
> row, column방향 모두 Stride설정이 가능하다.
>
> AlexNet의 경우에는 Spatial Complexity를 줄이기 위해 이 Stride를 사용하였다.
>
> ---
>
> #### 3. Receptive Field
>
> ![alt text](/assets/img/post/cnn/receptive_field.png)
>
> Layer를 여러개 쌓을 때 결과 값에 대한 Input Data를 의미한다.
>
> 예를 들어, 위의 마지막 Layer의 노란색 Pixel에 대한 Receptive Field는 맨 처음 Layer의 전체 Data가 될 것이다.
>
> 이 Receptive Field의 개념은 추후 모델 Architecture의 변화를 설명할 때, 자주 사용되기 때문에 반드시 숙지해 놓자.

### 3) CNN

![alt text](/assets/img/post/cnn/fcn_cnn.png)

> Convolution연산을 통해 얻은 데이터는 연산 과정을 보면 알 수 있듯이 이미지 전체에 대한 데이터라기 보다는, "부분 이미지에 대한 데이터의 모음"이라고 봐야 할 것이다.
>
> 즉, 전체적인 이미지에 대한 특징을 나타내는 Fully Connected Layer보다 해당 이미지를 해석하는데 도움이 된다.
>
> 이렇게 Convolution 연산을 활용하는 Layer로 구성된 Neural Network를 Convolutional Neural Network(CNN)이라고 한다.
>
> ---
>
> #### 활용
>
> ![alt text](/assets/img/post/cnn/cnn_application.png)
>
> CNN을 활용한 이미지 분류 Task는 크게 다음과 같이 나눠 볼 수 있다.
>
> 1. **Classification**<br>
>    : 어떤 이미지에 대해 그 이미지가 어떤 Label에 속하는 이미지인지 판별하는 문제
>
> 2. **Detection**<br>
>    : 이미지의 어떤 부분이 내가 원하는 Label에 속하고 있는지 찾아내는 문제
>
> 3. **Segmentation**<br>
>    : 이미지를 Pixel단위로 Classification하는 문제

### 4) Components

![alt text](/assets/img/post/cnn/cnn_components.png)

> CNN에는 Convolution Layer뿐만아니라 다양한 구성요소들이 복합적으로 존재한다.
>
> 따라서 이 요소들을 어떻게 조합하면 우리가 하고자 하는 Task에 최적의 Architecture를 만들 수 있는지 아는 것이 중요하다.
>
> ---
>
> 1. **Convolution Layer**<br>
>    : for feature extract
>
> 2. **Pooling Layers**<br>
>    : Down Sampling
>
> 3. **Fully Connected Layer**<br>
>    : for classification
>
> 4. **Activation Function**<br>
>    : ReLU, Sigmoid, tanh, ...
>
> 5. **Normalization**<br>
>    : $\hat{x}_{i, j} = \frac{x_{i, j}-\mu_j}{\sqrt{\sigma^2_j + \epsilon}}$

---

## 2./assets/img/post/cnn Level Classification

### 1) Preview

![alt text](/assets/img/post/cnn/cnn_architecture_error.png)

> 여기서는 Imagnet Large Scale Visual Recognition Challenge(이미지넷 이미지 인식 대회) 이하 ILSVRC에서의 우승 모델들에 대해 알아보면서 CNN의 /assets/img/post/cnn Level Classification이 어떻게 발전해왔고 어떤 방향으로 발전할 것인지 알아보고자 한다.
>
> ---
>
> CNN Architecture들은 주로 `Convolution Layer`, `Pooling Layer`, `Fully Connected Layer`로 이루어져있다.
>
> 이때, 초기 모델들의 발전과정을 잘 살펴 보면 `Fully Connected Layer`의 크기를 줄이는 방향으로 점점 바뀌게 된다는 것을 확인할 수 있다.
>
> 이 이유는 Parameter의 수가 늘어나면 늘어날수록 학습이 어렵고, Generalization성능이 줄어드는데,<br> > `Fully Connected Layer`는 그 특성상 매우 많은 수의 Parameter를 갖기 때문이다.
>
> 단, 그렇다고 Parameter수가 적은 것이 좋다는 것은 아니다.<br>
> 이는 Model의 Capacity와도 연관이 있기 때문인데, 따라서 후기 모델들은 이를 Architecture 설계를 통해 극복해 나가고 있다.
>
> |                    | Parameter $\Uparrow$ | Parameter $\Downarrow$ |
> | :----------------: | :------------------: | :--------------------: |
> |    **Accuracy**    |  $\uparrow$ (good)   |   $\downarrow$ (bad)   |
> |   **Complexity**   |   $\uparrow$ (bad)   |  $\downarrow$ (good)   |
> | **Generalization** |  $\downarrow$ (bad)  |   $\uparrow$ (good)    |
> |  **Overfitting**   |   $\uparrow$ (bad)   |  $\downarrow$ (good)   |
>
> 즉, 위와 같은 Trade Off가 존재하기 때문에 이를 고려한 Architecture 설계가 필요하다.
>
> 또 모델 Architecture를 분석하기 위해 Memory usage나 Parameter 개수, Flops를 계산할 수 있어야 한다.
>
> ---
>
> 1. **Convolution Output Size**<br> > $W_{out} = \frac{W-K_w+2P_w}{S_w} + 1$<br> > $H_{out} = \frac{H-K_h+2P_h}{S_h} + 1$ - 소수점이 있으면 버림
>
> 2. **Memory Usage**<br> > $Memory = \frac{Output Size \times 자료형크기}{1024}[KB]$ - Output Size = $C_{out} \times W_{out} \times H_{out}$ - 자료형 크기 = 4 (32-bit floating point)
>
> 3. **Learnable Params**<br> > $Params = C_{out} \times C_{in} \times K_w \times K_h + C_{out}$ - $C_{out} =$ Kernel의 개수 = Output Channel의 수 - $C_{in} =$ Kenel의 Channel수 = Input Channel의 수
>
> 4. **Number Of Flops**: 곱셈연산 개수<br> > $Flops = OutputSize \times KernelSize \times C_{in}$ - Output Size = $C_{out} \times W_{out} \times H_{out}$ - Kernel Size = $K_{w} \times K_{h}$

### 2) 2012-AlexNet

![alt text](/assets/img/post/cnn/alexnet.png)

> AlexNet은 2012년도 ILSVRC 우승 논문으로, <br>
> 처음으로 딥러닝 방식을 통해 기존 알고리즘들을 이기고 우승을 차지했다. <br>
> 이 논문 이후로는 모두 딥러닝방식들이 ILSVRC에서 우승하게 된다.
>
> 따라서, AlexNet은 현재 딥러닝 모델들의 기본적인 틀을 만들었다는 평가를 받고 있다.
>
> ---
>
> #### 주요 특징
>
> 1. **2개의 GPU사용**<br>
>    : 당시에는 GPU성능/용량이 좋지 않았기 때문에 2개의 3GB GPU에 나누어 학습하도록 구성함
>
> 2. **Local Response Normalization(LRN)**<br>
>    : 현재는 잘 사용하지 않는 기법이지만 AlexNet에서는 이 LRN을 처음으로 사용함
>
> 3. **CL: 5개, FCL: 3개**<br>
>    : 11, 5, 3 크기의 Convolution Kernel을 사용
>
> 4. **ReLU**사용
>
> 5. **DropOut** 사용<br>
>    : 깊어진 Network에서 과적합 방지를 위해 사용
>
> ---
>
> #### Layer별 분석
>
> ![alt text](/assets/img/post/cnn/alexnet_layer.png)
>
> _(Pooling Layer에는 Learnable Parameter가 없다.)_<br> > _(ReLU는 각 Convolution Layer 바로 뒤에 존재한다.)_
>
> |                | Memory Usage |  Parameter   | FLOP |
> | :------------: | :----------: | :----------: | :--: |
> | 주된 사용 위치 |      앞      | 뒤(FC Layer) | 중간 |
>
> ---
>
> #### 문제점
>
> - 뒤의 FC Layer가 너무 많은 Parameter를 갖는다.
> - 정확도를 높인 대신 Complexity가 매우 증가했다<br>
>   (Parameter수 &uparrow;, Memory Usage &uparrow;)
> - 사용 가능한 Memory의 한계 때문에 Layer의 깊이에 한계가 있다.

### 3) 2014-VGGNet

![alt text](/assets/img/post/cnn/vgg_architecture.png)

> VGGNet은 2014년도 ILSVRC의 준우승 논문으로 우승논문은 아니지만, 후에 나올 딥러닝의 방향을 제시한 논문이다.
>
> VGG는 Layer의 수에 따라 VGG16, VGG19로 나뉜다.
>
> ---
>
> #### 주요 특징
>
> VGG는 다음과 같은 목표를 가지고 Design되었다.
>
> - Simple(Regular) Design<br>
>
>   - Convolution = $(3 \times 3), 1S, 1P$
>   - Max Pool = $(2 \times 2), 2S$
>   - Doubling Channels after pool
>
> - Deeper Network
>   - Stage1: `Conv`-`Conv`-`Pool`
>   - Stage2: `Conv`-`Conv`-`Pool`
>   - Stage3: `Conv`-`Conv`-`Pool`
>   - Stage4: `Conv`-`Conv`-`Conv`-`Pool`
>   - Stage5: `Conv`-`Conv`-`Conv`-`Pool`
>
> > 즉, 오직 $3 \times 3$ 의 작은 Convolution Filter만을 사용하여 깊은 Layer를 구성하였다.
>
> _(참고)_<br> > *Fully Connected Layer에 `1*1` Convolution filter사용하였지만, 이것은 Parameter의 수를 줄이고자 한 것은 아니었다고 한다.\*
>
> ---
>
> #### 3x3 Convolution의 특징
>
> ![alt text](/assets/img/post/cnn/3x3convolution_benefit.png)
>
> $3 \times 3$ Convolution을 2개 사용하는 것과 <br> > $5 \times 5$ Convolution을 1개 사용하는 것의 차이를 살펴보자.
>
> 우선, 두 연산의 Receptive Field의 크기는 $5 \times 5$로 갖다.<br>
> 반면에 Parameter와 Flops에 있어서 차이가 존재하는데 이를 계산해 보자.
>
> - $5 \times 5$ Convolution<br>
>   Parameter: $5^2 \times C_{in} \times C_{out}$<br>
>   Flops: $5^2 \times C_{in} \times OutputSize$
>
> - $3 \times 3$ Convolution<br>
>   Parameter: $(3^2+3^2) \times C_{in} \times C_{out}$<br>
>   Flops: $(3^2+3^2) \times C_{in} \times OutputSize$
>
> > 즉, $3 \times 3$ Convolution을 사용하는 것이 다음과 같은 측면에서 좋다는 것을 알 수 있다.
> >
> > - Complexity를 낮출 수 있다.<br>
> >   (연산량과 Parameter모두 낮춘다)
> > - Non-Linear Activation Function을 많이 사용할 수 있다.
>
> ---
>
> #### Doubling Channels
>
> $3 \times 3$ Convolution을 사용하는 것이 연산량과 메모리 사용을 낮추어 준다는 측면에서 이득을 볼 수 있었다.<br>
>
> 하지만, 이것이 $3 \times 3$ Convolution을 사용하는 것이 항상 좋다것을 의미하지는 않다.
>
> Parameter가 줄어든다는 것은 Network의 Capacity가 줄어든다는 것이기 때문이다.
>
> 이를 보완하기 위해 VGG는 Pooling Layer이후에 Convolution과정에서 Channel을 Doubling해주어 Network에 충분한 Capacity를 보장해주고자 했다.

### 4) 2014-GoogleNet

![alt text](/assets/img/post/cnn/googlenet_architecture.png)

> #### 2014년도 ILSVRC 우승 논문
>
> GoogleNet은 2014년도 ILSVRC우승 논문으로 Inception Block을 통해 parameter수를 매우 적게 사용하여 좋은 성능을 낸 Architecture이다.
>
> ---
>
> #### Inception Block
>
> ![alt text](/assets/img/post/cnn/inception_block.png)
>
> 1. 하나의 입력에 대해 여러 결과를 만들고 이를 Concatenate한다.
>
> 2. $1 \times 1$ Convolution을 활용해 Parameter의 수를 매우 줄였다.
>
> ---
>
> #### $1 \times 1$ Convolution
>
> ![alt text](/assets/img/post/cnn/1x1convolution.png)
>
> 위의 그림을 보면 알 수 있듯이 $1 \times 1$ Convolution은 Channel의 깊이를 줄이는 역할을 한다.
>
> 즉, layer중간중간 이 $1 \times 1$ Convolution를 잘 활용할 경우 Parameter의 수를 줄이는데 매우 효과적이다.

### 5) 2015-ResNet

![alt text](/assets/img/post/cnn/resnet_architecture.png)

> 2015년도 ILSVRC 우승논문으로 Kaiming He가 고안한 Architecture이다.<br>
> 이전까지는 모델의 깊이가 깊어지면 오히려 성능이 안좋아 진다는 단점이 있었는데 이 논문은 이것을 해결하여 처음으로 사람의 능력을 이기는 모델을 만들었다.
>
> ---
>
> #### 주요 특징

1. Residual Block사용
   : 뒤의 내용 참조
   >
2. Skip Connection사용
   : 한 Layer의 Output을 몇개의 Layer를 건너뛴 후에 Input으로 추가하는 것을 말한다.
   >
3. Bottleneck Architecture사용
   : 뒤의 내용 참조
   >

---

#### Residual Block

<img src="https://velog.velcdn.com//assets/img/post/cnns/abrahamkim98/post/5baca652-1866-4608-93a9-154d5f8bf896//assets/img/post/cnn.png" width=470>
>
이전까지는 층이 깊어질수록 BackPropagate를 하면서 과거의 정보를 잃어 버리기 때문에 층을 늘리는데 한계가 존재했다.
>
ResNet에서는 이를 해결하기 위해 Residual Block을 활용했는데 Residual Block에서는 Skip Connection을 활용해 과거의 정보를 잃지 않도록 보완해 주었다.
>
---
#### Bottleneck Architecture
<img src="https://velog.velcdn.com//assets/img/post/cnns/abrahamkim98/post/bda8655b-c2e0-4ea0-be74-df3568ff30c1//assets/img/post/cnn.png" width=400>
>
GoogleNet에서 보았던 Inception Block과 비슷한데, 전체 Parameter의 수를 줄이기 위해 `3*3 Convolution`을 하기 전과 후에 `1*1 Convolution`을 사용해 주는 구조를 말한다.
>
---
>
Layer가 깊어질수록 발생하는 문제
>
![](https://velog.velcdn.com//assets/img/post/cnns/abrahamkim98/post/0ee39957-eb8a-4bf0-80d1-519da221eba0//assets/img/post/cnn.png)
>
1. Overfitting
2. gradient vanishing
>
즉, Generalize performance
>
---
#### 결과
<img src="https://velog.velcdn.com//assets/img/post/cnns/abrahamkim98/post/4ca05ac3-5644-4915-a4c5-fbc695f0cef6//assets/img/post/cnn.png">
>
위의 그림을 보면 알 수 있듯이 기존 모델에서는 OverFitting이 일어나지 않더라도 어느정도 층이 깊어지면 성능이 오히려 떨어지게 되는 경우가 많았다.
>
하지만 ResNet에서 제안한 방법을 사용할 경우, 층을 깊게 쌓더라도 성능이 떨어지지 않았고 오히려 적게 쌓은 모델보다 더 좋은 성능을 낼 수 있게 되었다.

### 6) DenseNet

<img src="https://velog.velcdn.com//assets/img/post/cnns/abrahamkim98/post/29f5f448-5f12-4fd7-9695-f5ae63759666//assets/img/post/cnn.png">

> 마지막으로, ILSVRC우승 논문은 아니지만, 컴퓨터 비전 분야에서 3대 학회로 불리는 CVPR에서 2017년도에 Best Paper를 받은 "Densely Connected Convolutional Networks"에 대해 알아보자.

---

#### 주요 특징

>

1. Dense Block을 사용
   >
2. Dense Block의 문제를 해결하기 위해 Transition Block을 사용
   >
3. Bottleneck Architecture사용
   >

---

>

#### Dense Block

> Dense Block의 큰 특징은 다음 두가지와 같다.
>
> > <img src="https://velog.velcdn.com//assets/img/post/cnns/abrahamkim98/post/07436260-a619-4122-b347-034895711e3b//assets/img/post/cnn.png" width=400>

1. Feed Forward시 각 Layer들을 다른 모든 Layer들과 연결한다.
   > ResNet에서는 다음의 Layer와 한번만 연결해 주었었다.
   >
   > DenseNet에서는 다음 Layer뿐만 아니라 그 뒤의 모든 Layer와 연결해 주고 있는 것을 확인할 수 있다.
   >
   > 이를 통해 얻을 수 있는 이점은 다음과 같다.

- Vanishing-Gradient 문제를 완화 할 수 있다.
- Feature Propagation을 강화 할 수 있다.
- Feature 의 재사용을 할 수 있다.
- Parameter 의 수를 줄일 수 있다.
  > > <img src="https://velog.velcdn.com//assets/img/post/cnns/abrahamkim98/post/ed3f6114-1c7d-4e55-a13f-127fa667be80//assets/img/post/cnn.png" width=400>

2. Skip Connection시에 Resnet에서 제안했던 Addition방법을 하는 대신에 Concatenation을 활용한다.
   > Resnet은 이전 값을 다음에 더해줌으로써 층을 쌓았는데, 이는 층이 깊어질 수록 계산량이 증폭되어 정보의 흐름(Information Flow)가 지연된다는 단점이 있었다.
   >
   > 이를 해결하기 위해 DenseNet에서는 Addition을 하는 것이 아니라, Contcatenate해 줌으로써 이를 해결해 주었다.
   >
   > 물론 Concatenate해 줌으로써 Output의 크기가 비약적으로 향상된다는 단점이 있는데, 이는 뒤의 Transition Block을 활용해 해결하고자 하였다.

---

>

#### Transition Block

> <img src="https://velog.velcdn.com//assets/img/post/cnns/abrahamkim98/post/0e85c675-ca2f-4c1e-b0ec-aa98a2dc1cb3//assets/img/post/cnn.png">
>
> DensBlock을 지날 경우 Concatenate연산에 의해 그 Output의 크기가 매우 커진다.
>
> 이를 해결하기 위해 위의 그림처럼 중간중간마다 Transition Block을 활용해 주었다.
>
> Transition Block은 `1*1 Convolution`과 Pooling작업을 통해 커진 Output을 다시 알맞은 크기로 변형시켜주는 역할을 한다.

---

[이미지 분류에 관한 다음내용](https://velog.io/@abrahamkim98/Deep-Learning%EC%8B%AC%ED%99%94-1.-CV)

---

# 추후 공부해볼 것

>

### 1) SENet

### 2) EfficientNet

### 3) Deformable Convolution
